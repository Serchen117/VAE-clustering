{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P18GBhN3g9R4"
      },
      "outputs": [],
      "source": [
        "!pip install emnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFLsRvblCZjK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.layers import *\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from keras.optimizers import SGD,Adam\n",
        "import imageio,os\n",
        "from PIL import Image\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from emnist import extract_training_samples, extract_test_samples\n",
        "from keras.regularizers import l1, l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2nkpbbsNus-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcPIbdEzCh-j"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "latent_dim = 20\n",
        "epochs = 100\n",
        "img_dim = 28\n",
        "filters = 16\n",
        "intermediate_dim = 256\n",
        "learning_rate = 0.005\n",
        "dataset = 'mnist'\n",
        "dataset = 'fashion'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elGRbd7HJ5WZ"
      },
      "outputs": [],
      "source": [
        "if dataset == 'mnist':\n",
        "  num_classes = 10\n",
        "  from keras.datasets import mnist\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "elif dataset == 'fashion':\n",
        "  num_classes = 10\n",
        "  from keras.datasets import fashion_mnist as mnist\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfdCctD1CnLC"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((-1, img_dim, img_dim, 1))\n",
        "x_test = x_test.reshape((-1, img_dim, img_dim, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHUK8omNCwyf"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "x = Input(shape=(img_dim, img_dim, 1))\n",
        "h = x\n",
        "\n",
        "h = Conv2D(filters=filters, kernel_size=3, strides=2, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2D(filters=filters, kernel_size=3, strides=1, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2D(filters=filters*2, kernel_size=3, strides=2, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2D(filters=filters*2, kernel_size=3, strides=1, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "\n",
        "h_shape = K.int_shape(h)[1:]\n",
        "h = Flatten()(h)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_var = Dense(latent_dim)(h)\n",
        "\n",
        "encoder = Model(x, z_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKbp0XliCzGf"
      },
      "outputs": [],
      "source": [
        "# decoder\n",
        "z = Input(shape=(latent_dim,))\n",
        "h = z\n",
        "h = Dense(np.prod(h_shape))(h)\n",
        "h = Reshape(h_shape)(h)\n",
        "h = Conv2DTranspose(filters=filters*2, kernel_size=3, strides=1, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2DTranspose(filters=filters*2, kernel_size=3, strides=2, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2DTranspose(filters=filters, kernel_size=3, strides=1, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "h = Conv2DTranspose(filters=filters, kernel_size=3, strides=2, padding='same')(h)\n",
        "h = LeakyReLU(0.2)(h)\n",
        "\n",
        "x_recon = Conv2DTranspose(filters=1,\n",
        "              kernel_size=3,\n",
        "              activation='sigmoid',\n",
        "              padding='same')(h)\n",
        "\n",
        "\n",
        "decoder = Model(z, x_recon)\n",
        "generator = decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_lVYQoYC2-8"
      },
      "outputs": [],
      "source": [
        "# classfier\n",
        "z = Input(shape=(latent_dim,))\n",
        "y = Dense(intermediate_dim, activation='relu')(z)\n",
        "y = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "classfier = Model(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKWtq3gkDEZ9"
      },
      "outputs": [],
      "source": [
        "# Reparameterization\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "x_recon = decoder(z)\n",
        "y = classfier(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhhoOnvEDKRf"
      },
      "outputs": [],
      "source": [
        "class Gaussian(Layer):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        self.num_classes = num_classes\n",
        "        super(Gaussian, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        latent_dim = input_shape[-1]\n",
        "        self.mean = self.add_weight(name='mean',\n",
        "                       shape=(self.num_classes, latent_dim),\n",
        "                       initializer='zeros')\n",
        "    def call(self, inputs):\n",
        "        z = inputs # z.shape=(batch_size, latent_dim)\n",
        "        z = K.expand_dims(z, 1)\n",
        "        return z - K.expand_dims(self.mean, 0)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_classes, input_shape[-1])\n",
        "\n",
        "gaussian = Gaussian(num_classes)\n",
        "z_prior_mean = gaussian(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ADtK8HjDZCf"
      },
      "outputs": [],
      "source": [
        "vae = Model(x, [x_recon, z_prior_mean, y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAzxOHOxDaNp"
      },
      "outputs": [],
      "source": [
        "# loss functions\n",
        "z_mean = K.expand_dims(z_mean, 1)\n",
        "z_log_var = K.expand_dims(z_log_var, 1)\n",
        "lamb = 1\n",
        "xent_loss = 0.5 * K.mean((x - x_recon)**2, 0)\n",
        "kl_loss = - 0.5 * (z_log_var - K.square(z_prior_mean))\n",
        "kl_loss = K.mean(K.batch_dot(K.expand_dims(y, 1), kl_loss), 0)\n",
        "cat_loss = K.mean(y * K.log(y + K.epsilon()), 0)\n",
        "vae_loss = lamb * K.sum(xent_loss) + K.sum(kl_loss) + K.sum(cat_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "va8cIKj2Dg5d"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "if not os.path.exists('compare'):\n",
        "    os.mkdir('compare')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = file_name,\n",
        "    save_freq='epoch',\n",
        "    period=10\n",
        ")\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "\n",
        "for i in range(epochs):\n",
        "  vae.fit(x_train,\n",
        "      shuffle=True,\n",
        "      epochs=1,\n",
        "      batch_size=batch_size,\n",
        "      validation_data=(x_test, None))\n",
        "      #callbacks=callbacks)\n",
        "\n",
        "  if i % 10 == 0:\n",
        "        x_test_encoded = encoder.predict(x_test)\n",
        "        recon = generator.predict(x_test_encoded)\n",
        "        n = 5\n",
        "        fig = np.zeros((img_dim * 2, img_dim * n))\n",
        "        for m in range(15, 20):\n",
        "            x_test_origin = x_test[m].reshape((img_dim, img_dim))\n",
        "            fig[0 * img_dim: (0 + 1) * img_dim,\n",
        "                (m - 15) * img_dim: ((m - 15) + 1) * img_dim] = x_test_origin\n",
        "\n",
        "            x_test_generate = recon[m].reshape((img_dim, img_dim))\n",
        "            fig[1 * img_dim: (1 + 1) * img_dim,\n",
        "                (m - 15) * img_dim: ((m - 15) + 1) * img_dim] = x_test_generate\n",
        "\n",
        "            fit_path = './compare/epoch' + str(i) + '_compare.png'\n",
        "            imageio.imwrite(fit_path, fig * 255)\n",
        "\n",
        "        fig_pil = Image.fromarray((fig * 255).astype(np.uint8))\n",
        "\n",
        "        display(fig_pil)\n",
        "vae.save(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLLpq11HDlcw"
      },
      "outputs": [],
      "source": [
        "means = K.eval(gaussian.mean)\n",
        "x_train_encoded = encoder.predict(x_train)\n",
        "y_train_pred = classfier.predict(x_train_encoded).argmax(axis=1)\n",
        "x_test_encoded = encoder.predict(x_test)\n",
        "y_test_pred = classfier.predict(x_test_encoded).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_e5Q99_DvBm"
      },
      "outputs": [],
      "source": [
        "def cluster_sample(path, category=0):\n",
        "    n = 8\n",
        "    figure = np.zeros((img_dim * n, img_dim * n))\n",
        "    idxs = np.where(y_train_pred == category)[0]\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            digit = x_train[np.random.choice(idxs)]\n",
        "            digit = digit.reshape((img_dim, img_dim))\n",
        "            figure[i * img_dim: (i + 1) * img_dim,\n",
        "            j * img_dim: (j + 1) * img_dim] = digit\n",
        "    imageio.imwrite(path, figure * 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwAm5JLpDwty"
      },
      "outputs": [],
      "source": [
        "def random_sample(path, category=0, std=1):\n",
        "    n = 8\n",
        "    figure = np.zeros((img_dim * n, img_dim * n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            noise_shape = (1, latent_dim)\n",
        "            z_sample = np.array(np.random.randn(*noise_shape)) * std + means[category]\n",
        "            x_recon = generator.predict(z_sample)\n",
        "            digit = x_recon[0].reshape((img_dim, img_dim))\n",
        "            figure[i * img_dim: (i + 1) * img_dim,\n",
        "            j * img_dim: (j + 1) * img_dim] = digit\n",
        "    imageio.imwrite(path, figure * 255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc-x9znHD3W_"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('samples'):\n",
        "    os.mkdir('samples')\n",
        "for i in range(10):\n",
        "    cluster_sample(u'samples/cluster_sample_%s.png' % i, i)\n",
        "    random_sample(u'samples/random_sample_%s.png' % i, i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZljLFz3EA46"
      },
      "outputs": [],
      "source": [
        "right = 0.\n",
        "for i in range(10):\n",
        "    _ = np.bincount(y_train[y_train_pred == i])\n",
        "    right += _.max()\n",
        "\n",
        "print (f'train acc: {right / len(y_train)}')\n",
        "\n",
        "\n",
        "right = 0.\n",
        "for i in range(10):\n",
        "    _ = np.bincount(y_test[y_test_pred == i])\n",
        "    right += _.max()\n",
        "\n",
        "print (f'test acc: {right / len(y_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5MR54BBSIsu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import adjusted_rand_score, mutual_info_score\n",
        "from sklearn.metrics import fowlkes_mallows_score\n",
        "# Calculate ARI\n",
        "ari_train = adjusted_rand_score(y_train, y_train_pred)\n",
        "ari_test = adjusted_rand_score(y_test, y_test_pred)\n",
        "# Calculate Mutual Information\n",
        "mi_train = mutual_info_score(y_train, y_train_pred)\n",
        "mi_test = mutual_info_score(y_test, y_test_pred)\n",
        "# Fowlkes-Mallows Index (FMI)\n",
        "score_train = fowlkes_mallows_score(y_train, y_train_pred)\n",
        "score_test = fowlkes_mallows_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"ARI for Training Set:\", ari_train)\n",
        "print(\"ARI for Test Set:\", ari_test)\n",
        "print(\"Mutual Information for Training Set:\", mi_train)\n",
        "print(\"Mutual Information for Test Set:\", mi_test)\n",
        "print(\"Fowlkes-Mallows Index for Training Set:\", score_train)\n",
        "print(\"Fowlkes-Mallows Index for Test Set:\", score_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxNvNMtQO3Td"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "x_test_2d = tsne.fit_transform(x_test_encoded)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "colors = \"red\", \"green\", \"blue\", \"cyan\", \"yellow\", \"magenta\", \"black\", \"orange\", \"purple\", \"pink\"\n",
        "for i, c, label in zip(range(num_classes), colors, range(num_classes)):\n",
        "    plt.scatter(x_test_2d[y_test_pred == i, 0], x_test_2d[y_test_pred == i, 1], c=c, label=label)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}